{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zoofs import ParticleSwarmOptimization\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'DDoS': 0,\n",
    "    'DoS': 1,\n",
    "    'Mirai': 2\n",
    "}\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: label_mapping.get(str(x), -1))  # Use -1 for unmatched labels if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'],axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, test_size = 0.2, shuffle=True,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_topass(model,X_train, y_train, X_valid, y_valid):      \n",
    "    model.fit(X_train,y_train)  \n",
    "    P = log_loss(y_valid,model.predict_proba(X_valid))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def objective_function_topass(model, X_train, y_train, X_valid, y_valid):      \n",
    "    \"\"\"\n",
    "    Objective function for optimization. Trains the model and evaluates F1 score.\n",
    "    Returns the negative F1 score to maximize it.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)  \n",
    "    P = f1_score(y_valid, y_pred, average='weighted')  # Weighted F1 score\n",
    "    return -P  # Negative F1 score to maximize it\n",
    "\n",
    "# Assuming ParticleSwarmOptimization is implemented and imported\n",
    "algo_object = ParticleSwarmOptimization(\n",
    "    objective_function_topass,\n",
    "    n_iteration=15,\n",
    "    population_size=30,\n",
    "    minimize=True\n",
    ")\n",
    "\n",
    "# Replace LightGBM model with XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric=\"logloss\"  # Evaluation metric for XGBoost\n",
    ")\n",
    "\n",
    "# Fit the optimization algorithm\n",
    "algo_object.fit(xgb_model, X_train, y_train, X_test, y_test, verbose=True)\n",
    "\n",
    "# Plot your results (if your ParticleSwarmOptimization class supports it)\n",
    "# algo_object.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_topass(model, X_train, y_train, X_valid, y_valid):      \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)  \n",
    "    P = f1_score(y_valid, y_pred)\n",
    "    return -P  # Return negative F1 score to maximize it\n",
    "\n",
    "    \n",
    "# create object of algorithm\n",
    "algo_object_pso=ParticleSwarmOptimization(objective_function_topass,n_iteration=15,\n",
    "                                    population_size=30,minimize=True)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier()                                       \n",
    "# fit the algorithm\n",
    "algo_object_pso.fit(lgb_model,X_train, y_train, X_test, y_test,verbose=True)\n",
    "#plot your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_xg = algo_object.best_feature_list\n",
    "feat_lg = algo_object_pso.best_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_object.plot_history()\n",
    "algo_object_pso.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train[feat_xg], y_train)\n",
    "y_pred=clf.predict(X_test[feat_xg])\n",
    "\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train[feat_lg], y_train)\n",
    "y_pred=clf.predict(X_test[feat_lg])\n",
    "\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoofs import HarrisHawkOptimization\n",
    "\n",
    "def objective_function_topass_harris(model,X_train, y_train, X_valid, y_valid):      \n",
    "    model.fit(X_train,y_train)  \n",
    "    P=f1_score(y_valid,model.predict_proba(X_valid))\n",
    "    return -P\n",
    "\n",
    "# import an algorithm !  \n",
    "\n",
    "\n",
    "# create object of algorithm\n",
    "algo_object_haris=HarrisHawkOptimization(objective_function_topass,\n",
    "                                   n_iteration=10,\n",
    "                                   population_size=30,\n",
    "                                   minimize=True)\n",
    "\n",
    "# fit the algorithm\n",
    "algo_object_haris.fit(lgb_model,X_train, y_train, X_test, y_test,verbose=True)\n",
    "\n",
    "#plot your results\n",
    "algo_object_haris.plot_history()\n",
    "\n",
    "# extract the best  feature set\n",
    "algo_object_haris.best_feature_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_object_haris.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_object_haris.best_feature_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_hawk = algo_object_haris.best_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train[feat_hawk], y_train)\n",
    "y_pred=clf.predict(X_test[feat_hawk])\n",
    "\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
